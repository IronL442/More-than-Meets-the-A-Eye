{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7782ba94",
   "metadata": {},
   "source": [
    "# Saliency Viewer\n",
    "Browse cached saliency predictions (NPY heatmaps), visualize as PNG heatmaps or overlays, and optionally inspect metrics.\n",
    "\n",
    "**Assumptions**\n",
    "- Predictions are stored under `predictions/{model}/{dataset}/{image_id}.npy`.\n",
    "- Original images are provided by the dataset adapter; for CAT2000 test set, you can point to the Stimuli folder.\n",
    "- PNG saving is optional; this notebook is primarily for interactive exploration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30ee36d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- imports ---\n",
    "import os, glob, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as W\n",
    "from IPython.display import display, clear_output\n",
    "import cv2\n",
    "\n",
    "# --- user-configurable defaults ---\n",
    "PRED_DIR = \"../predictions\"              # where .npy heatmaps are cached\n",
    "DATASETS_IMG_ROOTS = {\n",
    "    # Adjust per dataset. For CAT2000 official test set:\n",
    "    \"CAT2000\": \"../data/CAT2000/testSet/testSet/Stimuli\",\n",
    "    # If you have a flat images folder for another dataset:\n",
    "    \"folder\": \"..data/seminar_data/images\",\n",
    "}\n",
    "DEFAULT_DATASET = \"CAT2000\"\n",
    "\n",
    "# Colormap options (matplotlib)\n",
    "COLORMAPS = [\"gray\", \"jet\", \"turbo\", \"hot\", \"viridis\", \"inferno\", \"magma\", \"plasma\"]\n",
    "\n",
    "# Normalize modes for saliency display\n",
    "NORM_MODES = [\"max\", \"sum\", \"none\"]\n",
    "\n",
    "# If your metrics CSVs exist (runner outputs), we can load them\n",
    "METRICS_DIR = \"outputs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdf9845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- utilities ---\n",
    "def list_models(pred_root=PRED_DIR):\n",
    "    if not os.path.isdir(pred_root):\n",
    "        return []\n",
    "    return sorted([d for d in os.listdir(pred_root) if os.path.isdir(os.path.join(pred_root, d))])\n",
    "\n",
    "def list_datasets_for_model(model, pred_root=PRED_DIR):\n",
    "    path = os.path.join(pred_root, model)\n",
    "    if not os.path.isdir(path):\n",
    "        return []\n",
    "    return sorted([d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))])\n",
    "\n",
    "def list_image_ids(model, dataset, pred_root=PRED_DIR):\n",
    "    p = os.path.join(pred_root, model, dataset)\n",
    "    if not os.path.isdir(p):\n",
    "        return []\n",
    "    files = sorted(glob.glob(os.path.join(p, \"*.npy\")))\n",
    "    return [os.path.splitext(os.path.basename(f))[0] for f in files]\n",
    "\n",
    "def load_pred(model, dataset, image_id, pred_root=PRED_DIR):\n",
    "    f = os.path.join(pred_root, model, dataset, image_id + \".npy\")\n",
    "    m = np.load(f).astype(np.float32)\n",
    "    return m\n",
    "\n",
    "def find_image_file(dataset, image_id):\n",
    "    # try CAT2000 official first: Stimuli/<Category>/<Filename>.* where image_id might be 'Category_Filename'\n",
    "    stim_root = DATASETS_IMG_ROOTS.get(dataset)\n",
    "    if stim_root and os.path.isdir(stim_root):\n",
    "        # attempt parse Category_Filename\n",
    "        if \"_\" in image_id:\n",
    "            cat, stem = image_id.split(\"_\", 1)\n",
    "            for ext in [\".jpg\",\".jpeg\",\".png\",\".bmp\"]:\n",
    "                p = os.path.join(stim_root, cat, stem + ext)\n",
    "                if os.path.exists(p):\n",
    "                    return p\n",
    "        # fallback: recursive find by stem\n",
    "        stem = image_id\n",
    "        for ext in [\".jpg\",\".jpeg\",\".png\",\".bmp\"]:\n",
    "            cand = glob.glob(os.path.join(stim_root, \"*\", stem + ext))\n",
    "            if cand:\n",
    "                return cand[0]\n",
    "\n",
    "    # fallback flat images dir: data/<dataset>/images\n",
    "    flat = os.path.join(\"data\", dataset, \"images\", image_id + \".jpg\")\n",
    "    if os.path.exists(flat): return flat\n",
    "    flatp = os.path.join(\"data\", dataset, \"images\", image_id + \".png\")\n",
    "    if os.path.exists(flatp): return flatp\n",
    "    return None\n",
    "\n",
    "def normalize_map(m, mode=\"max\"):\n",
    "    m = m.astype(np.float32)\n",
    "    if mode == \"max\":\n",
    "        vmax = float(m.max())\n",
    "        if vmax > 0: m = m / vmax\n",
    "    elif mode == \"sum\":\n",
    "        s = float(m.sum())\n",
    "        if s > 0:\n",
    "            m = m / s\n",
    "            vmax = float(m.max())\n",
    "            if vmax > 0: m = m / vmax\n",
    "    m = np.clip(m, 0, 1)\n",
    "    return m\n",
    "\n",
    "def overlay_rgb(image_rgb, sal, alpha=0.5, cmap=\"jet\", norm=\"max\"):\n",
    "    if image_rgb is None:\n",
    "        return None\n",
    "    sal = normalize_map(sal, norm)\n",
    "    sal_u8 = (sal * 255).round().astype(np.uint8)\n",
    "    cmap_map = {\n",
    "        \"jet\": cv2.COLORMAP_JET,\n",
    "        \"turbo\": cv2.COLORMAP_TURBO if hasattr(cv2, \"COLORMAP_TURBO\") else cv2.COLORMAP_JET,\n",
    "        \"hot\": cv2.COLORMAP_HOT,\n",
    "        \"viridis\": cv2.COLORMAP_VIRIDIS if hasattr(cv2, \"COLORMAP_VIRIDIS\") else cv2.COLORMAP_JET,\n",
    "        \"inferno\": cv2.COLORMAP_INFERNO if hasattr(cv2, \"COLORMAP_INFERNO\") else cv2.COLORMAP_JET,\n",
    "        \"magma\": cv2.COLORMAP_MAGMA if hasattr(cv2, \"COLORMAP_MAGMA\") else cv2.COLORMAP_JET,\n",
    "        \"plasma\": cv2.COLORMAP_PLASMA if hasattr(cv2, \"COLORMAP_PLASMA\") else cv2.COLORMAP_JET,\n",
    "        \"gray\": cv2.COLORMAP_BONE,\n",
    "    }\n",
    "    cm_code = cmap_map.get(cmap.lower(), cv2.COLORMAP_JET)\n",
    "    heat_bgr = cv2.applyColorMap(sal_u8, cm_code)\n",
    "    img_bgr = cv2.cvtColor(image_rgb.astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
    "    alpha = float(np.clip(alpha, 0.0, 1.0))\n",
    "    beta = 1.0 - alpha\n",
    "    blended = cv2.addWeighted(img_bgr, beta, heat_bgr, alpha, 0.0)\n",
    "    return cv2.cvtColor(blended, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def imread_rgb(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    if img is None: return None\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2fa377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2aa49152935459088069cbf0b94af8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Model:', options=('blur_baseline', 'center_bias', 'deepgaze_v3', 'msi_net…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ef9d51105c4858997a960557dc6678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- widgets ---\n",
    "models = list_models()\n",
    "w_model = W.Dropdown(options=models, description=\"Model:\", disabled=False)\n",
    "w_dataset = W.Dropdown(options=[], description=\"Dataset:\", disabled=False)\n",
    "w_image = W.Dropdown(options=[], description=\"Image ID:\", disabled=False)\n",
    "\n",
    "w_cmap = W.Dropdown(options=COLORMAPS, value=\"jet\", description=\"Colormap:\")\n",
    "w_norm = W.Dropdown(options=NORM_MODES, value=\"max\", description=\"Normalize:\")\n",
    "w_alpha = W.FloatSlider(value=0.5, min=0.0, max=1.0, step=0.05, description=\"Overlay α:\")\n",
    "w_show_overlay = W.Checkbox(value=True, description=\"Show overlay\")\n",
    "w_save_png = W.Checkbox(value=False, description=\"Save PNGs on save click\")\n",
    "w_out_dir = W.Text(value=\"outputs/notebook_exports\", description=\"Out dir:\")\n",
    "w_refresh = W.Button(description=\"Refresh lists\", button_style=\"\")\n",
    "w_prev = W.Button(description=\"<< Prev\", button_style=\"\")\n",
    "w_next = W.Button(description=\"Next >>\", button_style=\"\")\n",
    "w_save = W.Button(description=\"Save current\", button_style=\"info\")\n",
    "\n",
    "left = W.VBox([w_model, w_dataset, w_image, w_cmap, w_norm, w_alpha, w_show_overlay, w_save_png, w_out_dir,\n",
    "               W.HBox([w_prev, w_next, w_refresh, w_save])])\n",
    "display(left)\n",
    "\n",
    "out = W.Output()\n",
    "display(out)\n",
    "\n",
    "def refresh_datasets(*_):\n",
    "    dss = list_datasets_for_model(w_model.value) if w_model.value else []\n",
    "    w_dataset.options = dss\n",
    "    if DEFAULT_DATASET in dss:\n",
    "        w_dataset.value = DEFAULT_DATASET\n",
    "    refresh_images()\n",
    "\n",
    "def refresh_images(*_):\n",
    "    ids = list_image_ids(w_model.value, w_dataset.value) if (w_model.value and w_dataset.value) else []\n",
    "    w_image.options = ids\n",
    "    if ids:\n",
    "        w_image.value = ids[0]\n",
    "    render()\n",
    "\n",
    "def step_image(delta):\n",
    "    ids = list(w_image.options)\n",
    "    if not ids: return\n",
    "    try:\n",
    "        idx = ids.index(w_image.value)\n",
    "    except ValueError:\n",
    "        idx = 0\n",
    "    idx = (idx + delta) % len(ids)\n",
    "    w_image.value = ids[idx]\n",
    "    render()\n",
    "\n",
    "def save_current(pred, img, base_out):\n",
    "    os.makedirs(base_out, exist_ok=True)\n",
    "    image_id = w_image.value\n",
    "    # heatmap only (normalized, colored)\n",
    "    plt.imsave(os.path.join(base_out, f\"{image_id}_heatmap.png\"),\n",
    "               normalize_map(pred, w_norm.value), cmap=w_cmap.value)\n",
    "    if img is not None:\n",
    "        ov = overlay_rgb(img, pred, alpha=w_alpha.value, cmap=w_cmap.value, norm=w_norm.value)\n",
    "        plt.imsave(os.path.join(base_out, f\"{image_id}_overlay.png\"), ov)\n",
    "\n",
    "def render(*_):\n",
    "    out.clear_output(wait=True)\n",
    "    if not (w_model.value and w_dataset.value and w_image.value):\n",
    "        with out: print(\"Select model, dataset, and image.\")\n",
    "        return\n",
    "    try:\n",
    "        pred = load_pred(w_model.value, w_dataset.value, w_image.value)\n",
    "    except Exception as e:\n",
    "        with out: print(\"Failed to load prediction:\", e)\n",
    "        return\n",
    "\n",
    "    img_path = find_image_file(w_dataset.value, w_image.value)\n",
    "    img = imread_rgb(img_path) if img_path else None\n",
    "\n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "        ncols = 2 if (w_show_overlay.value and img is not None) else 1\n",
    "        fig, axes = plt.subplots(1, ncols, figsize=(10 if ncols==1 else 16, 6))\n",
    "\n",
    "        if ncols == 1:\n",
    "            ax = axes\n",
    "            ax.set_title(\"Heatmap\")\n",
    "            ax.imshow(normalize_map(pred, w_norm.value), cmap=w_cmap.value)\n",
    "            ax.axis(\"off\")\n",
    "        else:\n",
    "            ax0, ax1 = axes\n",
    "            ax0.set_title(\"Heatmap\")\n",
    "            ax0.imshow(normalize_map(pred, w_norm.value), cmap=w_cmap.value)\n",
    "            ax0.axis(\"off\")\n",
    "\n",
    "            ax1.set_title(\"Overlay\")\n",
    "            ov = overlay_rgb(img, pred, alpha=w_alpha.value, cmap=w_cmap.value, norm=w_norm.value)\n",
    "            ax1.imshow(ov)\n",
    "            ax1.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "def on_refresh_clicked(_): refresh_datasets()\n",
    "def on_prev_clicked(_): step_image(-1)\n",
    "def on_next_clicked(_): step_image(+1)\n",
    "def on_save_clicked(_):\n",
    "    if not (w_model.value and w_dataset.value and w_image.value): return\n",
    "    pred = load_pred(w_model.value, w_dataset.value, w_image.value)\n",
    "    img_path = find_image_file(w_dataset.value, w_image.value)\n",
    "    img = imread_rgb(img_path) if img_path else None\n",
    "    base_out = os.path.join(w_out_dir.value, w_dataset.value, w_model.value)\n",
    "    save_current(pred, img, base_out)\n",
    "    if w_save_png.value:\n",
    "        print(f\"Saved PNGs to: {base_out}\")\n",
    "\n",
    "w_model.observe(lambda ch: refresh_datasets(), names=\"value\")\n",
    "w_dataset.observe(lambda ch: refresh_images(), names=\"value\")\n",
    "w_image.observe(lambda ch: render(), names=\"value\")\n",
    "w_cmap.observe(lambda ch: render(), names=\"value\")\n",
    "w_norm.observe(lambda ch: render(), names=\"value\")\n",
    "w_alpha.observe(lambda ch: render(), names=\"value\")\n",
    "w_show_overlay.observe(lambda ch: render(), names=\"value\")\n",
    "\n",
    "w_refresh.on_click(on_refresh_clicked)\n",
    "w_prev.on_click(on_prev_clicked)\n",
    "w_next.on_click(on_next_clicked)\n",
    "w_save.on_click(on_save_clicked)\n",
    "\n",
    "# initial population\n",
    "refresh_datasets()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea375fa",
   "metadata": {},
   "source": [
    "## (Optional) Metrics quicklook\n",
    "If you ran with metrics enabled, this cell will try to load summary CSVs from `outputs/*summary.csv` and display them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a73ce41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No summary CSVs found.\n"
     ]
    }
   ],
   "source": [
    "import glob, pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "def load_summaries(outputs_dir=METRICS_DIR):\n",
    "    csvs = glob.glob(os.path.join(outputs_dir, \"*__summary.csv\"))\n",
    "    dfs = []\n",
    "    for c in csvs:\n",
    "        try:\n",
    "            df = pd.read_csv(c)\n",
    "            df[\"__file\"] = os.path.basename(c)\n",
    "            dfs.append(df)\n",
    "        except Exception:\n",
    "            pass\n",
    "    if not dfs:\n",
    "        print(\"No summary CSVs found.\")\n",
    "        return None\n",
    "    all_df = pd.concat(dfs, ignore_index=True)\n",
    "    return all_df\n",
    "\n",
    "summ = load_summaries()\n",
    "if summ is not None:\n",
    "    display(summ.head(20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
